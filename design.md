

## 1. System Architecture

The AI Interview Assistant is organized into modular components. The following diagram illustrates the flow of data and responsibilities across the system:

```
+-------------------+
|   Student (User)  |
+-------------------+
        |
        v
+-------------------+
|   Streamlit UI    |
| - Voice Input     |
| - Text Input      |
| - Code Editor     |
| - Dashboard       |
+-------------------+
        |
        v
+---------------------------+
|       Backend API         |
|   (FastAPI / Flask)       |
|---------------------------|
| Interview Orchestrator    |
| NLP Engine (JD-aware Qs)  |
| TTS / ASR Module          |
| Coding Evaluation Module  |
+---------------------------+
        |
        v
+-------------------+
|   Database Layer  |
| - Transcripts     |
| - Answers         |
| - Scores          |
| - Job Context     |
+-------------------+
        |
        v
+-------------------+
|  Analytics Engine |
| - Per-Interview   |
| - Cumulative      |
| - Visualization   |
+-------------------+
        |
        v
+-------------------+
|   Feedback & UI   |
| - Reports         |
| - Recommendations |
| - Progress Trends |
+-------------------+
```

### Explanation of Components
- **Student (User)** â†’ The endâ€‘user interacts with the system through voice or text.  
- **Streamlit UI** â†’ Provides a simple, intuitive interface for interview setup, answering questions, coding practice, and viewing dashboards.  
- **Backend API (FastAPI/Flask)** â†’ Orchestrates the interview flow, generates JDâ€‘aware questions, handles speech/text conversion, and evaluates coding answers.  
- **Database Layer (SQLite/PostgreSQL)** â†’ Stores transcripts, answers, scores, and job context securely for later analysis.  
- **Analytics Engine** â†’ Processes stored data to generate perâ€‘interview metrics and cumulative performance trends.  
- **Feedback & UI** â†’ Presents reports, recommendations, and progress trends back to the student via the dashboard.  

---

# ğŸ“„ Design Document

## 1. ğŸ—ï¸ System Architecture
The solution is structured into modular components:

- **Frontend (UI/UX)** â†’ Streamlitâ€‘based interface with panels for preferences, interview, coding, and dashboard.  
- **Backend Orchestrator** â†’ Python modules managing interview flow, question delivery, and evaluation.  
- **Voice Module** â†’ ASR (speech recognition) + TTS for spoken interaction.  
- **LLM Engine** â†’ Lightweight models for Q&A and coding evaluation.  
- **Analytics Engine** â†’ Regressionâ€‘based models for perâ€‘interview and overall performance tracking.  
- **Data Layer** â†’ SQLite/PostgreSQL for storing interview logs, transcripts, and scores.  

---

## 2. ğŸ”„ Process Flow
1. **User Login / Preferences**  
   - Select LLM, input JD/company, choose interview type.  
2. **Interview Session**  
   - Questions delivered via text + TTS.  
   - Answers captured via speech or text.  
   - Coding round with integrated editor.  
3. **Evaluation**  
   - Perâ€‘interview analytics generated (time, length, tone, pauses, depth).  
   - Regression models compute overall performance trends.  
4. **Dashboard**  
   - Visual breakdown of strengths, weaknesses, and progress trends.  
   - Comparison across multiple sessions.  

---

## 3. ğŸ¨ UI Design
- **Preferences Panel** â†’ Dropdowns for LLM selection, JD/company input, start button.  
- **Interview Panel** â†’ Question display, voice prompt, answer capture, stop button.  
- **Coding Panel** â†’ Problem statement + code editor.  
- **Dashboard Panel** â†’ Charts (pie, line, bar) showing analytics and performance trends.  

---

## 4. âš™ï¸ Technology Stack
- **Frontend** â†’ Streamlit, Plotly/Altair for charts.  
- **Backend** â†’ Python (FastAPI/Flask optional for modular APIs).  
- **Voice** â†’ SpeechRecognition, gTTS.  
- **LLM** â†’ DistilBERT, GPT4All, or other small inference models.  
- **Analytics** â†’ scikitâ€‘learn regression models, pandas.  
- **Storage** â†’ SQLite/PostgreSQL.  

---

## 5. ğŸš€ Future Enhancements
- Cloud deployment with Docker + CI/CD.  
- Integration with larger LLMs for advanced evaluation.  
- Expanded analytics (domainâ€‘specific scoring, behavioral clustering).  

---

## ğŸ“Œ Document Metadata
- **Document Version**: 1.0  
- **Last Updated**: February 5, 2026  
- **Status**: Draft for Review  

---
